import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.types._
import org.apache.spark.sql.Row

// Initialize SparkSession
val spark = SparkSession.builder()
  .appName("CreateDataFrameExample")
  .master("local[*]")
  .getOrCreate()

import spark.implicits._

// Sample data
val data = Seq(
  ("Alice", "Engineering", "USA", 1000L),
  ("Bob", "HR", "UK", 1500L)
)

// Option 1: Using a case class (recommended)
case class Employee(name: String, department: String, country: String, salary: Long)
val df = spark.createDataFrame(data.map {
  case (a, b, c, d) => Employee(a, b, c, d)
})

df.show()
df.printSchema()